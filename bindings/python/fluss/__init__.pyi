# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

"""Type stubs for Fluss Python bindings."""

from types import TracebackType
from typing import Dict, List, Optional, Tuple

import pandas as pd
import pyarrow as pa

class Config:
    def __init__(self, properties: Optional[Dict[str, str]] = None) -> None: ...
    @property
    def bootstrap_server(self) -> Optional[str]: ...
    @bootstrap_server.setter
    def bootstrap_server(self, server: str) -> None: ...
    @property
    def request_max_size(self) -> int: ...
    @request_max_size.setter
    def request_max_size(self, size: int) -> None: ...
    @property
    def writer_batch_size(self) -> int: ...
    @writer_batch_size.setter
    def writer_batch_size(self, size: int) -> None: ...

class FlussConnection:
    @staticmethod
    async def connect(config: Config) -> FlussConnection: ...
    async def get_admin(self) -> FlussAdmin: ...
    async def get_table(self, table_path: TablePath) -> FlussTable: ...
    def close(self) -> None: ...
    def __enter__(self) -> FlussConnection: ...
    def __exit__(self, exc_type: Optional[type], exc_value: Optional[BaseException], traceback: Optional[TracebackType]) -> bool: ...
    def __repr__(self) -> str: ...

class FlussAdmin:
    async def create_table(
        self,
        table_path: TablePath,
        table_descriptor: TableDescriptor,
        ignore_if_exists: Optional[bool] = False,
    ) -> None: ...
    async def get_table(self, table_path: TablePath) -> TableInfo: ...
    async def get_latest_lake_snapshot(self, table_path: TablePath) -> LakeSnapshot: ...
    def __repr__(self) -> str: ...

class FlussTable:
    async def new_append_writer(self) -> AppendWriter: ...
    async def new_log_scanner(self) -> LogScanner: ...
    def get_table_info(self) -> TableInfo: ...
    def get_table_path(self) -> TablePath: ...
    def has_primary_key(self) -> bool: ...
    def __repr__(self) -> str: ...

class AppendWriter:
    async def append(self, row: dict | list | tuple) -> None:
        """Append a single row to the table.

        Args:
            row: Dictionary mapping field names to values, or
                 list/tuple of values in schema order

        Supported Types:
            Currently supports primitive types only:
            - Boolean, TinyInt, SmallInt, Int, BigInt (integers)
            - Float, Double (floating point)
            - String, Char (text)
            - Bytes, Binary (binary data)
            - Null values

            Temporal types (Date, Timestamp, Decimal) are not yet supported.

        Example:
            await writer.append({'id': 1, 'name': 'Alice', 'score': 95.5})
            await writer.append([1, 'Alice', 95.5])

        Note:
            For high-throughput bulk loading, prefer write_arrow_batch().
            Use flush() to ensure all queued records are sent and acknowledged.
        """
        ...
    def write_arrow(self, table: pa.Table) -> None: ...
    def write_arrow_batch(self, batch: pa.RecordBatch) -> None: ...
    def write_pandas(self, df: pd.DataFrame) -> None: ...
    def flush(self) -> None: ...
    def __repr__(self) -> str: ...

class LogScanner:
    def subscribe(
        self, start_timestamp: Optional[int], end_timestamp: Optional[int]
    ) -> None: ...
    def to_pandas(self) -> pd.DataFrame: ...
    def to_arrow(self) -> pa.Table: ...
    def __repr__(self) -> str: ...

class Schema:
    def __init__(self, schema: pa.Schema, primary_keys: Optional[List[str]] = None) -> None: ...
    def get_column_names(self) -> List[str]: ...
    def get_column_types(self) -> List[str]: ...
    def get_columns(self) -> List[Tuple[str,str]]: ...
    def __str__(self) -> str: ...

class TableDescriptor:
    def __init__(self, schema: Schema, **kwargs: str) -> None: ...
    def get_schema(self) -> Schema: ...

class TablePath:
    def __init__(self, database: str, table: str) -> None: ...
    @property
    def database_name(self) -> str: ...
    @property
    def table_name(self) -> str: ...
    def table_path_str(self) -> str: ...
    def __str__(self) -> str: ...
    def __repr__(self) -> str: ...
    def __hash__(self) -> int: ...
    def __eq__(self, other: object) -> bool: ...

class TableInfo:
    @property
    def table_id(self) -> int: ...
    @property
    def schema_id(self) -> int: ...
    @property
    def created_time(self) -> int: ...
    @property
    def modified_time(self) -> int: ...
    @property
    def table_path(self) -> TablePath: ...
    @property
    def num_buckets(self) -> int: ...
    @property
    def comment(self) -> Optional[str]: ...
    def get_primary_keys(self) -> List[str]: ...
    def get_bucket_keys(self) -> List[str]: ...
    def get_partition_keys(self) -> List[str]: ...
    def has_primary_key(self) -> bool: ...
    def is_partitioned(self) -> bool: ...
    def get_properties(self) -> Dict[str, str]: ...
    def get_custom_properties(self) -> Dict[str, str]: ...
    def get_schema(self) -> Schema: ...
    def get_column_names(self) -> List[str]: ...
    def get_column_count(self) -> int: ...

class FlussError(Exception):
    message: str
    def __init__(self, message: str) -> None: ...
    def __str__(self) -> str: ...

class LakeSnapshot:
    def __init__(self, snapshot_id: int) -> None: ...
    @property
    def snapshot_id(self) -> int: ...
    @property
    def table_buckets_offset(self) -> Dict[TableBucket, int]: ...
    def get_bucket_offset(self, bucket: TableBucket) -> Optional[int]: ...
    def get_table_buckets(self) -> List[TableBucket]: ...
    def __str__(self) -> str: ...
    def __repr__(self) -> str: ...

class TableBucket:
    def __init__(self, table_id: int, bucket: int) -> None: ...
    @staticmethod
    def with_partition(
        table_id: int, partition_id: int, bucket: int
    ) -> TableBucket: ...
    @property
    def table_id(self) -> int: ...
    @property
    def bucket_id(self) -> int: ...
    @property
    def partition_id(self) -> Optional[int]: ...
    def __hash__(self) -> int: ...
    def __eq__(self, other: object) -> bool: ...
    def __str__(self) -> str: ...
    def __repr__(self) -> str: ...

class TableDistribution:
    def bucket_keys(self) -> List[str]: ...
    def bucket_count(self) -> Optional[int]: ...

__version__: str
